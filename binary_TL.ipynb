{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.special import expit, logit\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple binary classifier\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_shape, 10) \n",
    "        self.layer_out = nn.Linear(10, 1) \n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = torch.relu(self.layer_1(inputs))\n",
    "        x = torch.relu(self.layer_out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, model, loss_fn, optimizer, epochs=5000, train_prop=1.0):\n",
    "    losses = []\n",
    "\n",
    "    # split into training and validation\n",
    "    n = len(Y)\n",
    "    X_train = X\n",
    "    Y_train = Y\n",
    "    X_validation = None\n",
    "    Y_validation = None\n",
    "    \n",
    "    # split into train and validation\n",
    "    if train_prop < 1.0:\n",
    "        xy = torch.cat((torch.unsqueeze(Y,1),X),axis=1)        \n",
    "        train_cutoff = int(n * train_prop)\n",
    "        train = xy[:train_cutoff,:]\n",
    "        Y_train, X_train =  train[:,0], train[:,1:]\n",
    "        \n",
    "        validation = xy[train_cutoff:,:]\n",
    "        Y_validation, X_validation = validation[:,0], validation[:, 1:]\n",
    "\n",
    "    \n",
    "    min_validation_loss = test = float(\"inf\")\n",
    "    min_validation_model = None\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        #calculate output\n",
    "        train_output = model(X_train)\n",
    "        \n",
    "        if train_prop < 1.0:\n",
    "            # calculate loss on validation set\n",
    "            # if it is smaller than the minimum validation loss, save the parameters\n",
    "            validation_output = model(X_validation)\n",
    "            validation_loss = loss_fn(validation_output, Y_validation.reshape(-1,1))\n",
    "            if validation_loss < min_validation_loss:\n",
    "                min_validation_model = copy.deepcopy(model)\n",
    "                min_validation_loss = validation_loss\n",
    "        \n",
    "        #calculate loss\n",
    "        train_loss = loss_fn(train_output, Y_train.reshape(-1,1))\n",
    "\n",
    "        #backprop\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(train_loss)\n",
    "    \n",
    "    # if no validation, return the final model\n",
    "    if train_prop == 1.0:\n",
    "        min_validation_model = model\n",
    "        \n",
    "    return(min_validation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train source model, target model w/o TL, target model w/ TL\n",
    "def training_loop(X_source_train, Y_source_train,\n",
    "                  X_source_test, Y_source_test,\n",
    "                  X_target_train, Y_target_train,\n",
    "                  X_target_test, Y_target_test):\n",
    "    random.seed(1978)\n",
    "    torch.manual_seed(1978)\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "    train_prop = 0.75\n",
    "    \n",
    "    \n",
    "    # Model , Optimizer, Loss\n",
    "    ###\n",
    "    # train source\n",
    "    ###\n",
    "    source_model = BinaryClassification(input_shape=X_source_train.shape[1])\n",
    "    optimizer = torch.optim.Adam(source_model.parameters(),lr=learning_rate)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    source_model = train(X_source_train, Y_source_train, source_model, loss_fn, optimizer, train_prop = train_prop)\n",
    "    \n",
    "    source_roc_auc = roc_auc_score(Y_source_test, source_model(X_source_test).detach().numpy())\n",
    "    print(f\"source auc:\\t{source_roc_auc}\")\n",
    "\n",
    "\n",
    "    \n",
    "    ###\n",
    "    # train target w/o TL\n",
    "    ###\n",
    "    target_model = BinaryClassification(input_shape=X_target_train.shape[1])\n",
    "    optimizer = torch.optim.Adam(target_model.parameters(),lr=learning_rate)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    target_model = train(X_target_train, Y_target_train, target_model, loss_fn, optimizer, train_prop = train_prop)\n",
    "\n",
    "    target_roc_auc = roc_auc_score(Y_target_test, target_model(X_target_test).detach().numpy())\n",
    "    print(f\"target auc:\\t{target_roc_auc}\")\n",
    "\n",
    "\n",
    "    ###\n",
    "    # train target w/ TL\n",
    "    ###\n",
    "    \n",
    "    target_model_tl = copy.deepcopy(source_model)\n",
    "    # freeze layers by so the weights do not update\n",
    "    for param in target_model_tl.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # reassing last layer with requires_grad=true by default\n",
    "    target_model_tl.layer_out = nn.Linear(target_model_tl.layer_out.in_features, target_model_tl.layer_out.out_features)\n",
    "\n",
    "    optimizer = torch.optim.Adam(target_model_tl.parameters(),lr=learning_rate)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    target_model_tl = train(X_target_train, Y_target_train, target_model_tl, loss_fn, optimizer, train_prop = train_prop)\n",
    "\n",
    "    target_tl_roc_auc = roc_auc_score(Y_target_test, target_model_tl(X_target_test).detach().numpy())\n",
    "    print(f\"target TL auc:\\t{target_tl_roc_auc}\") \n",
    "    \n",
    "    return(source_model,\n",
    "          target_model,\n",
    "          target_model_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_uniform(p, n, min_b, mean_b, meanX, sdX, train_prop = 1.0, seed = None):\n",
    "    \n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # generate uniform b's\n",
    "    low = min_b\n",
    "    high = (2*mean_b) - min_b\n",
    "    b = np.random.uniform(low, high, size=(p,1))\n",
    "    # normal X's\n",
    "    X = torch.from_numpy(np.random.normal(meanX, sdX, size=(n, p))).float()\n",
    "    \n",
    "    # logistic Y's\n",
    "    Y = torch.from_numpy(np.random.binomial(1, expit( np.matmul(X,b)))).float()\n",
    "    \n",
    "    # split into training and test\n",
    "    X_train = X\n",
    "    Y_train = Y\n",
    "    X_test = None\n",
    "    Y_test = None\n",
    "    \n",
    "    if train_prop < 1.0:\n",
    "        xy = torch.cat((Y,X),axis=1)        \n",
    "        train_cutoff = int(n * train_prop)\n",
    "        train = xy[:train_cutoff,:]\n",
    "        Y_train, X_train =  train[:,0], train[:,1:]\n",
    "        \n",
    "        test = xy[train_cutoff:,:]\n",
    "        Y_test, X_test = test[:,0], test[:, 1:]\n",
    "    \n",
    "    \n",
    "    return Y_train, X_train, Y_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_normal(p, n, mean_b, sd_b, meanX, sdX, train_prop = 1.0, seed=None):\n",
    "    \n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # generate normal b's\n",
    "    b = np.random.normal(mean_b, sd_b, size=(p,1))\n",
    "    # normal X's\n",
    "    X = torch.from_numpy(np.random.normal(meanX, sdX, size=(n, p))).float()\n",
    "    \n",
    "    # logistic Y's\n",
    "    Y = torch.from_numpy(np.random.binomial(1, expit( np.matmul(X,b)))).float()\n",
    "    \n",
    "    # split into training and test\n",
    "    X_train = X\n",
    "    Y_train = Y\n",
    "    X_test = None\n",
    "    Y_test = None\n",
    "\n",
    "\n",
    "    \n",
    "    if train_prop < 1.0:\n",
    "        xy = torch.cat((Y,X),axis=1)        \n",
    "        train_cutoff = int(n * train_prop)\n",
    "        train = xy[:train_cutoff,:]\n",
    "        Y_train, X_train =  train[:,0], train[:,1:]\n",
    "        \n",
    "        test = xy[train_cutoff:,:]\n",
    "        Y_test, X_test = test[:,0], test[:, 1:]\n",
    "    \n",
    "    \n",
    "    return Y_train, X_train, Y_test, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### same source and target, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source auc:\t0.9894212185942426\n",
      "target auc:\t0.6841787439613527\n",
      "target TL auc:\t0.818840579710145\n"
     ]
    }
   ],
   "source": [
    "seed = 1978\n",
    "\n",
    "p = 60\n",
    "\n",
    "# source params\n",
    "n_source = 1000\n",
    "min_b_source = 0.5\n",
    "mean_b_source = 10.0\n",
    "meanX_source = 0.0\n",
    "sdX_source = 1.0\n",
    "train_prop_source = 0.80\n",
    "\n",
    "# target params\n",
    "n_target = 200\n",
    "min_b_target = 0.5\n",
    "mean_b_target = 10.0\n",
    "meanX_target = 0.0\n",
    "sdX_target = 1.0\n",
    "train_prop_target = 0.50\n",
    "\n",
    "\n",
    "Y_source_train, X_source_train, Y_source_test, X_source_test = generate_data_uniform(p = p,\n",
    "                                                n = n_source,\n",
    "                                                 min_b = min_b_source,\n",
    "                                                 mean_b = mean_b_source,\n",
    "                                                 meanX =meanX_source,\n",
    "                                                 sdX = sdX_source,\n",
    "                                                 train_prop = train_prop_source,\n",
    "                                                seed = seed)\n",
    "\n",
    "    \n",
    "Y_target_train, X_target_train, Y_target_test, X_target_test = generate_data_uniform(p = p,\n",
    "                                                                n = n_target,\n",
    "                                                                 min_b = min_b_target,\n",
    "                                                                 mean_b = mean_b_target,\n",
    "                                                                 meanX =meanX_target,\n",
    "                                                                 sdX = sdX_target,\n",
    "                                                                 train_prop = train_prop_target,\n",
    "                                                                seed = seed)\n",
    "\n",
    "\n",
    "source_model, target_model, target_tl_model = training_loop(X_source_train, Y_source_train,\n",
    "                  X_source_test, Y_source_test,\n",
    "                  X_target_train, Y_target_train,\n",
    "                  X_target_test, Y_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4945, -0.5697,  1.4653,  ...,  1.2432,  0.9389, -0.4801],\n",
       "        [-1.0910, -0.6389,  0.8532,  ..., -1.1853,  0.4606,  0.8669],\n",
       "        [-0.8857,  1.1082, -2.2344,  ..., -0.6588,  0.1089,  1.4029],\n",
       "        ...,\n",
       "        [ 0.0568, -1.1793,  0.3054,  ..., -2.5236,  0.9449,  1.9006],\n",
       "        [ 0.1297,  0.4667,  0.2089,  ..., -1.2033,  0.5402, -1.6060],\n",
       "        [-0.1110,  0.4089,  1.5392,  ...,  0.2708,  0.7136, -0.4332]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_source_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_source_train.numpy()).to_csv(\"data/X_source_train.csv\", index=False, header=False)\n",
    "pd.DataFrame(Y_source_train.numpy()).to_csv(\"data/Y_source_train.csv\", index=False, header=False)\n",
    "pd.DataFrame(X_source_test.numpy()).to_csv(\"data/X_source_test.csv\", index=False, header=False)\n",
    "pd.DataFrame(Y_source_test.numpy()).to_csv(\"data/Y_source_test.csv\", index=False, header=False)\n",
    "#\n",
    "pd.DataFrame(X_target_train.numpy()).to_csv(\"data/X_target_train.csv\", index=False, header=False)\n",
    "pd.DataFrame(Y_target_train.numpy()).to_csv(\"data/Y_target_train.csv\", index=False, header=False)\n",
    "pd.DataFrame(X_target_test.numpy()).to_csv(\"data/X_target_test.csv\", index=False, header=False)\n",
    "pd.DataFrame(Y_target_test.numpy()).to_csv(\"data/Y_target_test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5505,  1.5966, -1.7085,  ...,  0.9672,  0.2403, -0.2485],\n",
       "        [ 0.0170,  0.4634, -0.2252,  ...,  0.3834, -0.2627,  1.1167],\n",
       "        [-0.7401, -2.3216,  2.5885,  ...,  0.2312, -0.5645,  1.1889],\n",
       "        ...,\n",
       "        [ 1.3207,  1.7277, -1.1563,  ..., -0.3781, -0.2164, -0.0283],\n",
       "        [-0.1596, -0.3747,  0.8926,  ...,  1.0048, -0.5351, -1.6187],\n",
       "        [-2.0624,  0.5458, -1.2427,  ...,  0.0154, -0.3726, -0.6892]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_source_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_np = t.numpy() #convert to Numpy array\n",
    "df = pd.DataFrame(t_np) #convert to a dataframe\n",
    "df.to_csv(\"testfile\",index=False) #save to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for param in target_tl_model.parameters():\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different parameterizations, both uniform\n",
    "change in mean_b_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source auc:\t0.9897836538461539\n",
      "target auc:\t0.6926770708283314\n",
      "target TL auc:\t0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "seed = 1978\n",
    "\n",
    "p = 60\n",
    "\n",
    "# source params\n",
    "n_source = 1000\n",
    "min_b_source = 0.5\n",
    "mean_b_source = 5.0\n",
    "meanX_source = 0.0\n",
    "sdX_source = 1.0\n",
    "train_prop_source = 0.80\n",
    "\n",
    "# target params\n",
    "n_target = 200\n",
    "min_b_target = 0.5\n",
    "mean_b_target = 5.0\n",
    "meanX_target = 0.0\n",
    "sdX_target = 1.0\n",
    "train_prop_target = 0.50\n",
    "\n",
    "\n",
    "Y_source_train, X_source_train, Y_source_test, X_source_test = generate_data_uniform(p = p,\n",
    "                                                n = n_source,\n",
    "                                                 min_b = min_b_source,\n",
    "                                                 mean_b = mean_b_source,\n",
    "                                                 meanX =meanX_source,\n",
    "                                                 sdX = sdX_source,\n",
    "                                                 train_prop = train_prop_source,\n",
    "                                                seed = seed)\n",
    "                                                         \n",
    "    \n",
    "Y_target_train, X_target_train, Y_target_test, X_target_test = generate_data_uniform(p = p,\n",
    "                                                                n = n_target,\n",
    "                                                                 min_b = min_b_target,\n",
    "                                                                 mean_b = mean_b_target,\n",
    "                                                                 meanX =meanX_target,\n",
    "                                                                 sdX = sdX_target,\n",
    "                                                                 train_prop = train_prop_target,\n",
    "                                                                seed = seed)\n",
    "\n",
    "\n",
    "source_model, target_model, target_tl_model = training_loop(X_source_train, Y_source_train,\n",
    "                  X_source_test, Y_source_test,\n",
    "                  X_target_train, Y_target_train,\n",
    "                  X_target_test, Y_target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### source and target normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source auc:\t0.9729770531400965\n",
      "target auc:\t0.5390499194847022\n",
      "target TL auc:\t0.6167471819645732\n"
     ]
    }
   ],
   "source": [
    "seed = 1978\n",
    "p = 60\n",
    "\n",
    "# source params\n",
    "n_source = 1000\n",
    "mean_b_source = 0.0\n",
    "sd_b_source = 3.0\n",
    "meanX_source = 0.0\n",
    "sdX_source = 1.0\n",
    "train_prop_source = 0.80\n",
    "\n",
    "# target params\n",
    "n_target = 200\n",
    "mean_b_target = 0.0\n",
    "sd_b_target = 3.0\n",
    "meanX_target = 0.0\n",
    "sdX_target = 1.0\n",
    "train_prop_target = 0.50\n",
    "\n",
    "\n",
    "Y_source_train, X_source_train, Y_source_test, X_source_test = generate_data_normal(p = p,\n",
    "                                                n = n_source,\n",
    "                                                 mean_b = mean_b_source,\n",
    "                                                 sd_b =sd_b_source,\n",
    "                                                 meanX =meanX_source,\n",
    "                                                 sdX = sdX_source,\n",
    "                                                 train_prop = train_prop_source,\n",
    "                                                seed = seed)\n",
    "                                                         \n",
    "    \n",
    "Y_target_train, X_target_train, Y_target_test, X_target_test = generate_data_normal(p = p,\n",
    "                                                                n = n_target,\n",
    "                                                                 mean_b = mean_b_target,\n",
    "                                                                 sd_b = sd_b_target,\n",
    "                                                                 meanX =meanX_target,\n",
    "                                                                 sdX = sdX_target,\n",
    "                                                                 train_prop = train_prop_target,\n",
    "                                                                seed = seed)\n",
    "\n",
    "\n",
    "source_model, target_model, target_tl_model = training_loop(X_source_train, Y_source_train,\n",
    "                  X_source_test, Y_source_test,\n",
    "                  X_target_train, Y_target_train,\n",
    "                  X_target_test, Y_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### source normal target uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source auc:\t0.962155388471178\n",
      "target auc:\t0.6787439613526571\n",
      "target TL auc:\t0.48731884057971014\n"
     ]
    }
   ],
   "source": [
    "seed = 1978\n",
    "p = 60\n",
    "\n",
    "# source params\n",
    "n_source = 1000\n",
    "mean_b_source = 0.0\n",
    "sd_b_source = 3.0\n",
    "meanX_source = 0.0\n",
    "sdX_source = 1.0\n",
    "train_prop_source = 0.80\n",
    "\n",
    "# target params\n",
    "n_target = 200\n",
    "mean_b_target = 0.0\n",
    "sd_b_target = 3.0\n",
    "meanX_target = 0.0\n",
    "sdX_target = 1.0\n",
    "train_prop_target = 0.50\n",
    "\n",
    "\n",
    "n_target = 200\n",
    "min_b_target = 0.5\n",
    "mean_b_target = 5.0\n",
    "meanX_target = 0.0\n",
    "sdX_target = 1.0\n",
    "train_prop_target = 0.50\n",
    "\n",
    "Y_source_train, X_source_train, Y_source_test, X_source_test = generate_data_normal(p = p,\n",
    "                                                n = n_source,\n",
    "                                                 mean_b = mean_b_source,\n",
    "                                                 sd_b =sd_b_source,\n",
    "                                                 meanX =meanX_source,\n",
    "                                                 sdX = sdX_source,\n",
    "                                                 train_prop = train_prop_source,\n",
    "                                                seed = seed)\n",
    "\n",
    "Y_target_train, X_target_train, Y_target_test, X_target_test = generate_data_uniform(p = p,\n",
    "                                                                n = n_target,\n",
    "                                                                 min_b = min_b_target,\n",
    "                                                                 mean_b = mean_b_target,\n",
    "                                                                 meanX =meanX_target,\n",
    "                                                                 sdX = sdX_target,\n",
    "                                                                 train_prop = train_prop_target,\n",
    "                                                                seed = seed)\n",
    "\n",
    "\n",
    "source_model, target_model, target_tl_model = training_loop(X_source_train, Y_source_train,\n",
    "                  X_source_test, Y_source_test,\n",
    "                  X_target_train, Y_target_train,\n",
    "                  X_target_test, Y_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
